GRPO Training Pipeline

4 Main Steps:

Generate Completions
From various prompts using the current model (policy).

Compute Rewards & Advantages
Use a reward model (RM) to evaluate completions.
Normalize scores to compute advantages (how good is each output relative to average).

Estimate KL Divergence
Compare current policy to reference policy (e.g., SFT checkpoint) to ensure stability.

Compute Loss & Update Model
Final objective = Advantage â€“ KL penalty.
Maximize good completions while avoiding harmful policy drift.
